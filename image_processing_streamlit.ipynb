{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H_YwAh09X7_"
      },
      "source": [
        "# All-in-one Image Processing Web (Streamlit + Colab)\n",
        "\n",
        "Notebook nÃ y táº¡o **web xá»­ lÃ½ áº£nh** cho 8 tuáº§n:\n",
        "\n",
        "- Week01: digital imaging fundamentals  \n",
        "- Week02: point processing  \n",
        "- Week03: histogram processing  \n",
        "- Week04: spatial filtering  \n",
        "- Week05: frequency domain  \n",
        "- Week06: PCA & compression  \n",
        "- Week07: restoration & morphology  \n",
        "- Week08: segmentation & JPEG-like\n",
        "\n",
        "CÃ¡c bÆ°á»›c sá»­ dá»¥ng:\n",
        "\n",
        "1. Cháº¡y tá»«ng cell tá»« trÃªn xuá»‘ng (hoáº·c **Run all**).\n",
        "2. Láº¥y link web tá»« ngrok (cell 4).\n",
        "3. Giá»¯ cell cuá»‘i (Streamlit) Ä‘ang cháº¡y trong khi dÃ¹ng web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR9ivwpL9X8A",
        "outputId": "beb87744-d74b-46a7-d1c8-d26be10f5062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit opencv-python-headless scikit-image scikit-learn pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wpev1S59X8B"
      },
      "source": [
        "## BÆ°á»›c 2 â€” Nháº­p ngrok token\n",
        "\n",
        "VÃ o [dashboard ngrok](https://dashboard.ngrok.com/get-started/your-authtoken) â†’ copy **authtoken** â†’ dÃ¡n vÃ o biáº¿n dÆ°á»›i."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1CzTI1H9X8B",
        "outputId": "4e38a365-c5b4-490d-cccf-1729aa912794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ngrok token set xong.\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"35iphLCtrywMBsKK94ktKM7iqnz_4MkbZHdAt8eW3bfiASu5k\"\n",
        "\n",
        "if NGROK_AUTH_TOKEN.startswith(\"PASTE_\"):\n",
        "    print(\"ChÆ°a thay token.\")\n",
        "else:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"Ngrok token set xong.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YajI_ge9X8B"
      },
      "source": [
        "## BÆ°á»›c 3 â€” Táº¡o file `app.py` chá»©a toÃ n bá»™ code web xá»­ lÃ½ áº£nh\n",
        "\n",
        "Cell dÆ°á»›i sáº½ ghi file `app.py` trong mÃ´i trÆ°á»ng Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgIkq93T9X8C",
        "outputId": "6fc116cf-9eb5-4993-c719-0677856f1c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import streamlit as st\n",
        "from sklearn.decomposition import PCA\n",
        "from skimage import morphology, util\n",
        "\n",
        "# ================== Helper ==================\n",
        "\n",
        "def read_image(file) -> np.ndarray:\n",
        "    \"\"\"Read uploaded image -> RGB uint8\"\"\"\n",
        "    bytes_data = file.read()\n",
        "    img_array = np.frombuffer(bytes_data, np.uint8)\n",
        "    bgr = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "    return rgb\n",
        "\n",
        "def to_gray(img_rgb: np.ndarray) -> np.ndarray:\n",
        "    if len(img_rgb.shape) == 2:\n",
        "        return img_rgb\n",
        "    return cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "def normalize_to_uint8(img: np.ndarray) -> np.ndarray:\n",
        "    img = np.nan_to_num(img)\n",
        "    img_min, img_max = img.min(), img.max()\n",
        "    if img_max - img_min < 1e-5:\n",
        "        return np.zeros_like(img, dtype=np.uint8)\n",
        "    img_norm = (img - img_min) / (img_max - img_min)\n",
        "    return (img_norm * 255).astype(np.uint8)\n",
        "\n",
        "# ================== CÃ¡c thuáº­t toÃ¡n ==================\n",
        "\n",
        "# ---- Week 01: fundamentals ----\n",
        "\n",
        "def w1_to_grayscale(img):\n",
        "    return to_gray(img)\n",
        "\n",
        "def w1_resize(img, scale):\n",
        "    h, w = img.shape[:2]\n",
        "    new_size = (int(w * scale), int(h * scale))\n",
        "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def w1_rotate(img, angle):\n",
        "    h, w = img.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
        "    return cv2.warpAffine(img, M, (w, h))\n",
        "\n",
        "# ---- Week 02: point processing ----\n",
        "\n",
        "def w2_negative(img):\n",
        "    return 255 - img\n",
        "\n",
        "def w2_log_transform(img, c=1.0):\n",
        "    img_gray = to_gray(img)\n",
        "    img_norm = img_gray / 255.0\n",
        "    log_img = c * np.log(1 + img_norm)\n",
        "    return normalize_to_uint8(log_img)\n",
        "\n",
        "def w2_gamma_correction(img, gamma=1.0):\n",
        "    img_norm = img / 255.0\n",
        "    corrected = np.power(img_norm, gamma)\n",
        "    return (corrected * 255).astype(np.uint8)\n",
        "\n",
        "def w2_contrast_stretch(img, m1=50, m2=200):\n",
        "    img_gray = to_gray(img).astype(np.float32)\n",
        "    out = np.zeros_like(img_gray)\n",
        "\n",
        "    img_gray = np.clip(img_gray, 0, 255)\n",
        "\n",
        "    # piecewise linear\n",
        "    out[img_gray < m1] = (img_gray[img_gray < m1] / m1) * 50\n",
        "    mid_mask = (img_gray >= m1) & (img_gray <= m2)\n",
        "    out[mid_mask] = 50 + (img_gray[mid_mask] - m1) * (205 / (m2 - m1))\n",
        "    out[img_gray > m2] = 255\n",
        "    return out.astype(np.uint8)\n",
        "\n",
        "# ---- Week 03: histogram processing ----\n",
        "\n",
        "def w3_hist_equalization(img):\n",
        "    gray = to_gray(img)\n",
        "    eq = cv2.equalizeHist(gray)\n",
        "    return eq\n",
        "\n",
        "def w3_clahe(img, clip=2.0, tile=8):\n",
        "    gray = to_gray(img)\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(tile, tile))\n",
        "    cl = clahe.apply(gray)\n",
        "    return cl\n",
        "\n",
        "# ---- Week 04: spatial filtering ----\n",
        "\n",
        "def w4_mean_filter(img, k=3):\n",
        "    return cv2.blur(img, (k, k))\n",
        "\n",
        "def w4_gaussian_filter(img, k=5, sigma=1.0):\n",
        "    return cv2.GaussianBlur(img, (k, k), sigma)\n",
        "\n",
        "def w4_median_filter(img, k=3):\n",
        "    return cv2.medianBlur(img, k)\n",
        "\n",
        "def w4_sharpen(img):\n",
        "    kernel = np.array([[0, -1, 0],\n",
        "                       [-1, 5, -1],\n",
        "                       [0, -1, 0]])\n",
        "    return cv2.filter2D(img, -1, kernel)\n",
        "\n",
        "def w4_sobel_edge(img):\n",
        "    gray = to_gray(img)\n",
        "    gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    mag = np.sqrt(gx**2 + gy**2)\n",
        "    return normalize_to_uint8(mag)\n",
        "\n",
        "# ---- Week 05: frequency domain ----\n",
        "\n",
        "def w5_ideal_lowpass(img, cutoff=30):\n",
        "    gray = to_gray(img)\n",
        "    f = np.fft.fft2(gray)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "\n",
        "    rows, cols = gray.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "    mask = np.zeros_like(gray, dtype=np.float32)\n",
        "    Y, X = np.ogrid[:rows, :cols]\n",
        "    dist = np.sqrt((Y - crow)**2 + (X - ccol)**2)\n",
        "    mask[dist <= cutoff] = 1\n",
        "\n",
        "    fshift_filtered = fshift * mask\n",
        "    f_ishift = np.fft.ifftshift(fshift_filtered)\n",
        "    img_back = np.fft.ifft2(f_ishift)\n",
        "    img_back = np.abs(img_back)\n",
        "    return normalize_to_uint8(img_back)\n",
        "\n",
        "def w5_ideal_highpass(img, cutoff=30):\n",
        "    gray = to_gray(img)\n",
        "    f = np.fft.fft2(gray)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "\n",
        "    rows, cols = gray.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "    mask = np.ones_like(gray, dtype=np.float32)\n",
        "    Y, X = np.ogrid[:rows, :cols]\n",
        "    dist = np.sqrt((Y - crow)**2 + (X - ccol)**2)\n",
        "    mask[dist <= cutoff] = 0\n",
        "\n",
        "    fshift_filtered = fshift * mask\n",
        "    f_ishift = np.fft.ifftshift(fshift_filtered)\n",
        "    img_back = np.fft.ifft2(f_ishift)\n",
        "    img_back = np.abs(img_back)\n",
        "    return normalize_to_uint8(img_back)\n",
        "\n",
        "# ---- Week 06: PCA + compression ----\n",
        "\n",
        "def w6_pca_compress(img, n_components=50):\n",
        "    \"\"\"Simple PCA trÃªn áº£nh grayscale.\"\"\"\n",
        "    gray = to_gray(img).astype(np.float32) / 255.0\n",
        "    h, w = gray.shape\n",
        "    # PCA trÃªn chiá»u rá»™ng\n",
        "    from sklearn.decomposition import PCA\n",
        "    pca = PCA(n_components=min(n_components, w))\n",
        "    transformed = pca.fit_transform(gray)\n",
        "    reconstructed = pca.inverse_transform(transformed)\n",
        "    rec = normalize_to_uint8(reconstructed)\n",
        "    return rec\n",
        "\n",
        "# ---- Week 07: restoration + morphology ----\n",
        "\n",
        "def w7_add_gaussian_noise(img, mean=0, sigma=20):\n",
        "    noisy = img.astype(np.float32) + np.random.normal(mean, sigma, img.shape)\n",
        "    noisy = np.clip(noisy, 0, 255)\n",
        "    return noisy.astype(np.uint8)\n",
        "\n",
        "def w7_median_denoise(img, k=3):\n",
        "    return cv2.medianBlur(img, k)\n",
        "\n",
        "def w7_morphology_operation(img, op=\"erode\", k=3):\n",
        "    gray = to_gray(img)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((k, k), np.uint8)\n",
        "    if op == \"erode\":\n",
        "        result = cv2.erode(binary, kernel, iterations=1)\n",
        "    elif op == \"dilate\":\n",
        "        result = cv2.dilate(binary, kernel, iterations=1)\n",
        "    elif op == \"open\":\n",
        "        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
        "    elif op == \"close\":\n",
        "        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "    else:\n",
        "        result = binary\n",
        "    return result\n",
        "\n",
        "# ---- Week 08: segmentation + \"JPEG\" style ----\n",
        "\n",
        "def w8_global_threshold(img, thresh=128):\n",
        "    gray = to_gray(img)\n",
        "    _, binary = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)\n",
        "    return binary\n",
        "\n",
        "def w8_otsu_threshold(img):\n",
        "    gray = to_gray(img)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "def w8_kmeans_segmentation(img, k=3):\n",
        "    Z = img.reshape((-1, 3))\n",
        "    Z = np.float32(Z)\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    K = k\n",
        "    ret, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "    center = np.uint8(center)\n",
        "    res = center[label.flatten()]\n",
        "    return res.reshape((img.shape))\n",
        "\n",
        "def w8_block_dct_compress(img, q=20):\n",
        "    \"\"\"ÄÆ¡n giáº£n hoÃ¡ kiá»ƒu JPEG: DCT theo block 8x8 trÃªn grayscale.\"\"\"\n",
        "    gray = to_gray(img).astype(np.float32) - 128\n",
        "    h, w = gray.shape\n",
        "    h8 = h - h % 8\n",
        "    w8 = w - w % 8\n",
        "    gray = gray[:h8, :w8]\n",
        "    out = np.zeros_like(gray)\n",
        "\n",
        "    Q = np.ones((8, 8), np.float32) * q\n",
        "\n",
        "    for i in range(0, h8, 8):\n",
        "        for j in range(0, w8, 8):\n",
        "            block = gray[i:i+8, j:j+8]\n",
        "            dct = cv2.dct(block)\n",
        "            dct_q = np.round(dct / Q)\n",
        "            block_rec = cv2.idct(dct_q * Q)\n",
        "            out[i:i+8, j:j+8] = block_rec\n",
        "\n",
        "    out = out + 128\n",
        "    return normalize_to_uint8(out)\n",
        "\n",
        "# ================== UI Streamlit ==================\n",
        "\n",
        "st.set_page_config(page_title=\"Image Processing Toolkit\", layout=\"wide\")\n",
        "st.title(\"Image Processing Toolkit (8 tuáº§n)\")\n",
        "\n",
        "st.sidebar.header(\"Chá»n áº£nh\")\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload image (JPG/PNG)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = read_image(uploaded_file)\n",
        "    st.subheader(\"áº¢nh gá»‘c\")\n",
        "    st.image(img, use_column_width=True)\n",
        "else:\n",
        "    st.info(\"Upload 1 áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u.\")\n",
        "    st.stop()\n",
        "\n",
        "st.sidebar.header(\"Chá»n tuáº§n & thuáº­t toÃ¡n\")\n",
        "\n",
        "week = st.sidebar.selectbox(\n",
        "    \"Chá»n tuáº§n\",\n",
        "    [\n",
        "        \"Week01 - Digital imaging fundamentals\",\n",
        "        \"Week02 - Point processing\",\n",
        "        \"Week03 - Histogram processing\",\n",
        "        \"Week04 - Spatial filtering\",\n",
        "        \"Week05 - Frequency domain\",\n",
        "        \"Week06 - PCA & compression\",\n",
        "        \"Week07 - Restoration & morphology\",\n",
        "        \"Week08 - Segmentation & JPEG\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "result = None  # processed image\n",
        "extra_info = \"\"\n",
        "\n",
        "# ---------------- Week 1 ----------------\n",
        "if week.startswith(\"Week01\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Grayscale\", \"Resize (scale)\", \"Rotate\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"Grayscale\":\n",
        "        result = w1_to_grayscale(img)\n",
        "\n",
        "    elif algo == \"Resize (scale)\":\n",
        "        scale = st.sidebar.slider(\"Scale\", 0.1, 2.0, 0.5, 0.1)\n",
        "        result = w1_resize(img, scale)\n",
        "        extra_info = f\"Scale = {scale}\"\n",
        "\n",
        "    elif algo == \"Rotate\":\n",
        "        angle = st.sidebar.slider(\"GÃ³c quay (Ä‘á»™)\", -180, 180, 45, 5)\n",
        "        result = w1_rotate(img, angle)\n",
        "        extra_info = f\"Angle = {angle}Â°\"\n",
        "\n",
        "# ---------------- Week 2 ----------------\n",
        "elif week.startswith(\"Week02\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Negative\", \"Log transform\", \"Gamma correction\", \"Contrast stretching\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"Negative\":\n",
        "        result = w2_negative(img)\n",
        "\n",
        "    elif algo == \"Log transform\":\n",
        "        c = st.sidebar.slider(\"c\", 0.5, 5.0, 1.0, 0.1)\n",
        "        result = w2_log_transform(img, c=c)\n",
        "        extra_info = f\"c = {c}\"\n",
        "\n",
        "    elif algo == \"Gamma correction\":\n",
        "        gamma = st.sidebar.slider(\"gamma\", 0.1, 3.0, 1.2, 0.1)\n",
        "        result = w2_gamma_correction(img, gamma)\n",
        "        extra_info = f\"gamma = {gamma}\"\n",
        "\n",
        "    elif algo == \"Contrast stretching\":\n",
        "        m1 = st.sidebar.slider(\"m1\", 0, 255, 50, 1)\n",
        "        m2 = st.sidebar.slider(\"m2\", 0, 255, 200, 1)\n",
        "        if m2 <= m1:\n",
        "            st.warning(\"m2 pháº£i > m1\")\n",
        "        else:\n",
        "            result = w2_contrast_stretch(img, m1, m2)\n",
        "            extra_info = f\"m1={m1}, m2={m2}\"\n",
        "\n",
        "# ---------------- Week 3 ----------------\n",
        "elif week.startswith(\"Week03\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Histogram equalization\", \"CLAHE\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"Histogram equalization\":\n",
        "        result = w3_hist_equalization(img)\n",
        "\n",
        "    elif algo == \"CLAHE\":\n",
        "        clip = st.sidebar.slider(\"clip limit\", 1.0, 10.0, 2.0, 0.5)\n",
        "        tile = st.sidebar.slider(\"tile size\", 2, 16, 8, 1)\n",
        "        result = w3_clahe(img, clip, tile)\n",
        "        extra_info = f\"clip={clip}, tile={tile}\"\n",
        "\n",
        "# ---------------- Week 4 ----------------\n",
        "elif week.startswith(\"Week04\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Mean filter\", \"Gaussian filter\", \"Median filter\", \"Sharpen\", \"Sobel edge\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"Mean filter\":\n",
        "        k = st.sidebar.slider(\"Kernel size\", 3, 15, 3, 2)\n",
        "        result = w4_mean_filter(img, k)\n",
        "        extra_info = f\"k={k}\"\n",
        "\n",
        "    elif algo == \"Gaussian filter\":\n",
        "        k = st.sidebar.slider(\"Kernel size\", 3, 31, 5, 2)\n",
        "        sigma = st.sidebar.slider(\"Sigma\", 0.1, 10.0, 1.0, 0.1)\n",
        "        result = w4_gaussian_filter(img, k, sigma)\n",
        "        extra_info = f\"k={k}, sigma={sigma}\"\n",
        "\n",
        "    elif algo == \"Median filter\":\n",
        "        k = st.sidebar.slider(\"Kernel size\", 3, 15, 3, 2)\n",
        "        result = w4_median_filter(img, k)\n",
        "        extra_info = f\"k={k}\"\n",
        "\n",
        "    elif algo == \"Sharpen\":\n",
        "        result = w4_sharpen(img)\n",
        "\n",
        "    elif algo == \"Sobel edge\":\n",
        "        result = w4_sobel_edge(img)\n",
        "\n",
        "# ---------------- Week 5 ----------------\n",
        "elif week.startswith(\"Week05\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Ideal low-pass\", \"Ideal high-pass\"]\n",
        "    )\n",
        "    cutoff = st.sidebar.slider(\"Cutoff frequency\", 5, 200, 30, 5)\n",
        "\n",
        "    if algo == \"Ideal low-pass\":\n",
        "        result = w5_ideal_lowpass(img, cutoff)\n",
        "    elif algo == \"Ideal high-pass\":\n",
        "        result = w5_ideal_highpass(img, cutoff)\n",
        "\n",
        "    extra_info = f\"cutoff={cutoff}\"\n",
        "\n",
        "# ---------------- Week 6 ----------------\n",
        "elif week.startswith(\"Week06\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"PCA compression (grayscale)\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"PCA compression (grayscale)\":\n",
        "        n_components = st.sidebar.slider(\"Sá»‘ thÃ nh pháº§n PCA\", 5, 200, 50, 5)\n",
        "        result = w6_pca_compress(img, n_components)\n",
        "        extra_info = f\"n_components={n_components}\"\n",
        "\n",
        "# ---------------- Week 7 ----------------\n",
        "elif week.startswith(\"Week07\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Add Gaussian noise\", \"Median denoise\", \"Morphology (erode/dilate/open/close)\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"Add Gaussian noise\":\n",
        "        sigma = st.sidebar.slider(\"Sigma noise\", 1, 80, 20, 1)\n",
        "        result = w7_add_gaussian_noise(img, sigma=sigma)\n",
        "        extra_info = f\"sigma={sigma}\"\n",
        "\n",
        "    elif algo == \"Median denoise\":\n",
        "        k = st.sidebar.slider(\"Kernel size\", 3, 15, 3, 2)\n",
        "        result = w7_median_denoise(img, k)\n",
        "        extra_info = f\"k={k}\"\n",
        "\n",
        "    elif algo == \"Morphology (erode/dilate/open/close)\":\n",
        "        op = st.sidebar.selectbox(\"Operation\", [\"erode\", \"dilate\", \"open\", \"close\"])\n",
        "        k = st.sidebar.slider(\"Kernel size\", 3, 15, 3, 2)\n",
        "        result = w7_morphology_operation(img, op, k)\n",
        "        extra_info = f\"op={op}, k={k}\"\n",
        "\n",
        "# ---------------- Week 8 ----------------\n",
        "elif week.startswith(\"Week08\"):\n",
        "    algo = st.sidebar.selectbox(\n",
        "        \"Thuáº­t toÃ¡n\",\n",
        "        [\"Global threshold\", \"Otsu threshold\", \"K-means segmentation\", \"Block DCT (JPEG-like)\"]\n",
        "    )\n",
        "\n",
        "    if algo == \"Global threshold\":\n",
        "        t = st.sidebar.slider(\"Threshold\", 0, 255, 128, 1)\n",
        "        result = w8_global_threshold(img, t)\n",
        "        extra_info = f\"thresh={t}\"\n",
        "\n",
        "    elif algo == \"Otsu threshold\":\n",
        "        result = w8_otsu_threshold(img)\n",
        "\n",
        "    elif algo == \"K-means segmentation\":\n",
        "        k = st.sidebar.slider(\"K (clusters)\", 2, 8, 3, 1)\n",
        "        result = w8_kmeans_segmentation(img, k)\n",
        "        extra_info = f\"k={k}\"\n",
        "\n",
        "    elif algo == \"Block DCT (JPEG-like)\":\n",
        "        q = st.sidebar.slider(\"Q (quantization strength)\", 5, 80, 20, 5)\n",
        "        result = w8_block_dct_compress(img, q)\n",
        "        extra_info = f\"Q={q}\"\n",
        "\n",
        "# ================== Hiá»ƒn thá»‹ káº¿t quáº£ ==================\n",
        "\n",
        "st.subheader(\"áº¢nh sau xá»­ lÃ½\")\n",
        "if extra_info:\n",
        "    st.caption(extra_info)\n",
        "\n",
        "if result is not None:\n",
        "    st.image(result, use_column_width=True)\n",
        "else:\n",
        "    st.warning(\"ChÆ°a chá»n thuáº­t toÃ¡n hoáº·c thuáº­t toÃ¡n chÆ°a tráº£ ra káº¿t quáº£.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_qkWf4y9X8C"
      },
      "source": [
        "## BÆ°á»›c 4 â€” Má»Ÿ ngrok tunnel cho cá»•ng 8501\n",
        "\n",
        "Cháº¡y cell nÃ y Ä‘á»ƒ láº¥y URL public truy cáº­p web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJvEq-m-9X8D",
        "outputId": "391917d6-f0d2-42b5-d2f4-5e28e6fbb3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Public URL: NgrokTunnel: \"https://hydrologically-unsubsiding-natosha.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Rhq2qT9X8D"
      },
      "source": [
        "## BÆ°á»›c 5 â€” Cháº¡y Streamlit\n",
        "\n",
        "Giá»¯ cell nÃ y **Ä‘ang cháº¡y** trong khi má»Ÿ web á»Ÿ URL á»Ÿ trÃªn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAvdraco9X8D",
        "outputId": "62968a96-e687-4cd5-f916-23216ace4e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 02:05:42.646 \n",
            "Warning: the config option 'server.enableCORS=false' is not compatible with\n",
            "'server.enableXsrfProtection=true'.\n",
            "As a result, 'server.enableCORS' is being overridden to 'true'.\n",
            "\n",
            "More information:\n",
            "In order to protect against CSRF attacks, we send a cookie with each request.\n",
            "To do so, we must specify allowable origins, which places a restriction on\n",
            "cross-origin resource sharing.\n",
            "\n",
            "If cross origin resource sharing is required, please disable server.enableXsrfProtection.\n",
            "            \n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.6.17.95:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-11-20 02:08:35.281 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:08:35.380 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:08:49.432 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:08:49.556 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:00.213 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:00.387 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:10.333 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:10.384 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:24.491 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:24.689 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:32.220 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:32.415 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:33.039 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:33.434 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:34.071 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:34.174 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:34.704 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:34.907 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:35.817 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:35.859 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:36.357 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:36.519 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:36.886 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:37.078 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:37.319 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:37.675 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:37.946 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:38.064 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:38.265 MediaFileHandler: Missing file 340ecf24fb687bd50c3257f79e09d2a38716c99f74fa2d2a9f4f8196.jpg\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 140, in get_file\n",
            "    return self._files_by_id[file_id]\n",
            "           ~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: '340ecf24fb687bd50c3257f79e09d2a38716c99f74fa2d2a9f4f8196'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/media_file_handler.py\", line 95, in validate_absolute_path\n",
            "    self._storage.get_file(absolute_path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 142, in get_file\n",
            "    raise MediaFileStorageError(\n",
            "streamlit.runtime.media_file_storage.MediaFileStorageError: Bad filename '340ecf24fb687bd50c3257f79e09d2a38716c99f74fa2d2a9f4f8196.jpg'. (No media file with id '340ecf24fb687bd50c3257f79e09d2a38716c99f74fa2d2a9f4f8196')\n",
            "2025-11-20 02:09:38.733 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:38.793 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:39.286 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "2025-11-20 02:09:39.487 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py --server.port 8501 --server.headless true --server.enableCORS false"
      ]
    }
  ]
}